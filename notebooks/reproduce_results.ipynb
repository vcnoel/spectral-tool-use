{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Spectral Analysis Reproduction\n",
                "\n",
                "This notebook reproduces the key experimental results from the paper. It loads the pre-computed spectral sweep data and baseline perplexity/logprob data to generate the comparative metrics (AUC, Precision, Recall) reported in the tables."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "from sklearn.metrics import roc_auc_score, precision_recall_curve\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set paths\n",
                "DATA_DIR = Path('../data')\n",
                "BASELINE_DIR = DATA_DIR / 'baselines'\n",
                "SWEEP_DIR = DATA_DIR / 'categories_sweeps'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_metrics(y_true, y_score):\n",
                "    \"\"\"Calculate AUC, Best Precision, and Best Recall.\"\"\"\n",
                "    try:\n",
                "        auc = roc_auc_score(y_true, y_score)\n",
                "    except ValueError:\n",
                "        auc = 0.5\n",
                "\n",
                "    precisions, recalls, thresholds = precision_recall_curve(y_true, y_score)\n",
                "    f1s = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)\n",
                "    best_idx = np.argmax(f1s)\n",
                "    \n",
                "    return auc, precisions[best_idx], recalls[best_idx]\n",
                "\n",
                "def analyze_discriminator(df, score_col, label_col='is_hallucination', invert=False):\n",
                "    \"\"\"Analyze a single feature as a discriminator.\"\"\"\n",
                "    y = df[label_col].values\n",
                "    scores = df[score_col].values\n",
                "    \n",
                "    if invert:\n",
                "        scores = -scores\n",
                "        \n",
                "    # Auto-detect direction if not strictly specified, but for reproduction we usually fix it.\n",
                "    # Here, we check correlation to align with the paper's 'best direction' approach.\n",
                "    corr = np.corrcoef(y, scores)[0,1]\n",
                "    if np.isnan(corr): corr = 0\n",
                "    \n",
                "    final_scores = scores if corr > 0 else -scores\n",
                "    direction = '+' if corr > 0 else '-'\n",
                "    \n",
                "    auc, prec, rec = get_metrics(y, final_scores)\n",
                "    return auc, prec, rec, direction"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Baseline Analysis (PPL & LogProb)\n",
                "\n",
                "Reproduces the PPL and Min LogProb baselines table."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline_files = list(BASELINE_DIR.glob('*_ppl.csv'))\n",
                "baseline_results = []\n",
                "\n",
                "for f in baseline_files:\n",
                "    df = pd.read_csv(f)\n",
                "    name = f.stem.replace('_ppl', '').replace('_', ' ').title()\n",
                "    \n",
                "    # PPL Analysis\n",
                "    p_auc, p_prec, p_rec, p_dir = analyze_discriminator(df, 'ppl')\n",
                "    \n",
                "    # Min LogProb Analysis\n",
                "    # Note: paper uses 'logprob_min' for stronger baselines\n",
                "    l_auc, l_prec, l_rec, l_dir = analyze_discriminator(df, 'logprob_min')\n",
                "    \n",
                "    baseline_results.append({\n",
                "        'Dataset': name,\n",
                "        'N': len(df),\n",
                "        'Hallucinations': df['is_hallucination'].sum(),\n",
                "        'PPL AUC': p_auc,\n",
                "        'PPL Prec': p_prec,\n",
                "        'PPL Rec': p_rec,\n",
                "        'LogProb AUC': l_auc,\n",
                "        'LogProb Prec': l_prec,\n",
                "        'LogProb Rec': l_rec\n",
                "    })\n",
                "\n",
                "df_base = pd.DataFrame(baseline_results)\n",
                "display(df_base.round(4))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Spectral Sweep Analysis\n",
                "\n",
                "Reproduces the per-category spectral analysis (HFER, Fiedler, etc.)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sweep_files = list(SWEEP_DIR.glob('*.csv'))\n",
                "sweep_results = []\n",
                "\n",
                "spectral_metrics = ['HFER', 'Fiedler_E_val', 'smoothness_entropy', 'spectral_entropy']\n",
                "\n",
                "for f in sweep_files:\n",
                "    try:\n",
                "        df = pd.read_csv(f)\n",
                "        if 'is_hallucination' not in df.columns:\n",
                "            continue\n",
                "            \n",
                "        name = f.stem.replace('mistral_', '').capitalize()\n",
                "        \n",
                "        row = {'Category': name, 'N': len(df)}\n",
                "        \n",
                "        for metric in spectral_metrics:\n",
                "            auc, prec, rec, _ = analyze_discriminator(df, metric)\n",
                "            row[f'{metric} AUC'] = auc\n",
                "            \n",
                "        sweep_results.append(row)\n",
                "    except Exception as e:\n",
                "        print(f\"Skipping {f.name}: {e}\")\n",
                "\n",
                "df_sweep = pd.DataFrame(sweep_results)\n",
                "display(df_sweep.round(4))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}